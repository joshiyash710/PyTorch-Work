{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9cf2fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad8b0be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8681b35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b5016f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['id','Unnamed: 32'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18b63986",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(df.iloc[:,1:],df.iloc[:,0],test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08a362a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.130</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.69</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.1166</td>\n",
       "      <td>0.1922</td>\n",
       "      <td>0.32150</td>\n",
       "      <td>0.16280</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>19.270</td>\n",
       "      <td>26.47</td>\n",
       "      <td>127.90</td>\n",
       "      <td>1162.0</td>\n",
       "      <td>0.09401</td>\n",
       "      <td>0.17190</td>\n",
       "      <td>0.16570</td>\n",
       "      <td>0.07593</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>0.06261</td>\n",
       "      <td>...</td>\n",
       "      <td>24.15</td>\n",
       "      <td>30.90</td>\n",
       "      <td>161.40</td>\n",
       "      <td>1813.0</td>\n",
       "      <td>0.1509</td>\n",
       "      <td>0.6590</td>\n",
       "      <td>0.60910</td>\n",
       "      <td>0.17850</td>\n",
       "      <td>0.3672</td>\n",
       "      <td>0.11230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15.340</td>\n",
       "      <td>14.26</td>\n",
       "      <td>102.50</td>\n",
       "      <td>704.4</td>\n",
       "      <td>0.10730</td>\n",
       "      <td>0.21350</td>\n",
       "      <td>0.20770</td>\n",
       "      <td>0.09756</td>\n",
       "      <td>0.2521</td>\n",
       "      <td>0.07032</td>\n",
       "      <td>...</td>\n",
       "      <td>18.07</td>\n",
       "      <td>19.08</td>\n",
       "      <td>125.10</td>\n",
       "      <td>980.9</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.5954</td>\n",
       "      <td>0.63050</td>\n",
       "      <td>0.23930</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.09946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>13.370</td>\n",
       "      <td>16.39</td>\n",
       "      <td>86.10</td>\n",
       "      <td>553.5</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0.07325</td>\n",
       "      <td>0.08092</td>\n",
       "      <td>0.02800</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>0.05823</td>\n",
       "      <td>...</td>\n",
       "      <td>14.26</td>\n",
       "      <td>22.75</td>\n",
       "      <td>91.99</td>\n",
       "      <td>632.1</td>\n",
       "      <td>0.1025</td>\n",
       "      <td>0.2531</td>\n",
       "      <td>0.33080</td>\n",
       "      <td>0.08978</td>\n",
       "      <td>0.2048</td>\n",
       "      <td>0.07628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>12.700</td>\n",
       "      <td>12.17</td>\n",
       "      <td>80.88</td>\n",
       "      <td>495.0</td>\n",
       "      <td>0.08785</td>\n",
       "      <td>0.05794</td>\n",
       "      <td>0.02360</td>\n",
       "      <td>0.02402</td>\n",
       "      <td>0.1583</td>\n",
       "      <td>0.06275</td>\n",
       "      <td>...</td>\n",
       "      <td>13.65</td>\n",
       "      <td>16.92</td>\n",
       "      <td>88.12</td>\n",
       "      <td>566.9</td>\n",
       "      <td>0.1314</td>\n",
       "      <td>0.1607</td>\n",
       "      <td>0.09385</td>\n",
       "      <td>0.08224</td>\n",
       "      <td>0.2775</td>\n",
       "      <td>0.09464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>11.060</td>\n",
       "      <td>14.96</td>\n",
       "      <td>71.49</td>\n",
       "      <td>373.9</td>\n",
       "      <td>0.10330</td>\n",
       "      <td>0.09097</td>\n",
       "      <td>0.05397</td>\n",
       "      <td>0.03341</td>\n",
       "      <td>0.1776</td>\n",
       "      <td>0.06907</td>\n",
       "      <td>...</td>\n",
       "      <td>11.92</td>\n",
       "      <td>19.90</td>\n",
       "      <td>79.76</td>\n",
       "      <td>440.0</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.22990</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.3301</td>\n",
       "      <td>0.09080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>13.380</td>\n",
       "      <td>30.72</td>\n",
       "      <td>86.34</td>\n",
       "      <td>557.2</td>\n",
       "      <td>0.09245</td>\n",
       "      <td>0.07426</td>\n",
       "      <td>0.02819</td>\n",
       "      <td>0.03264</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.06016</td>\n",
       "      <td>...</td>\n",
       "      <td>15.05</td>\n",
       "      <td>41.61</td>\n",
       "      <td>96.69</td>\n",
       "      <td>705.6</td>\n",
       "      <td>0.1172</td>\n",
       "      <td>0.1421</td>\n",
       "      <td>0.07003</td>\n",
       "      <td>0.07763</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.07675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>12.830</td>\n",
       "      <td>15.73</td>\n",
       "      <td>82.89</td>\n",
       "      <td>506.9</td>\n",
       "      <td>0.09040</td>\n",
       "      <td>0.08269</td>\n",
       "      <td>0.05835</td>\n",
       "      <td>0.03078</td>\n",
       "      <td>0.1705</td>\n",
       "      <td>0.05913</td>\n",
       "      <td>...</td>\n",
       "      <td>14.09</td>\n",
       "      <td>19.35</td>\n",
       "      <td>93.22</td>\n",
       "      <td>605.8</td>\n",
       "      <td>0.1326</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.34760</td>\n",
       "      <td>0.09783</td>\n",
       "      <td>0.3006</td>\n",
       "      <td>0.07802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>9.876</td>\n",
       "      <td>17.27</td>\n",
       "      <td>62.92</td>\n",
       "      <td>295.4</td>\n",
       "      <td>0.10890</td>\n",
       "      <td>0.07232</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.01952</td>\n",
       "      <td>0.1934</td>\n",
       "      <td>0.06285</td>\n",
       "      <td>...</td>\n",
       "      <td>10.42</td>\n",
       "      <td>23.22</td>\n",
       "      <td>67.08</td>\n",
       "      <td>331.6</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>0.06213</td>\n",
       "      <td>0.05588</td>\n",
       "      <td>0.2989</td>\n",
       "      <td>0.07380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>9.405</td>\n",
       "      <td>21.70</td>\n",
       "      <td>59.60</td>\n",
       "      <td>271.2</td>\n",
       "      <td>0.10440</td>\n",
       "      <td>0.06159</td>\n",
       "      <td>0.02047</td>\n",
       "      <td>0.01257</td>\n",
       "      <td>0.2025</td>\n",
       "      <td>0.06601</td>\n",
       "      <td>...</td>\n",
       "      <td>10.85</td>\n",
       "      <td>31.24</td>\n",
       "      <td>68.73</td>\n",
       "      <td>359.4</td>\n",
       "      <td>0.1526</td>\n",
       "      <td>0.1193</td>\n",
       "      <td>0.06141</td>\n",
       "      <td>0.03770</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>0.08304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "565       20.130         28.25          131.20     1261.0          0.09780   \n",
       "33        19.270         26.47          127.90     1162.0          0.09401   \n",
       "22        15.340         14.26          102.50      704.4          0.10730   \n",
       "124       13.370         16.39           86.10      553.5          0.07115   \n",
       "418       12.700         12.17           80.88      495.0          0.08785   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "342       11.060         14.96           71.49      373.9          0.10330   \n",
       "455       13.380         30.72           86.34      557.2          0.09245   \n",
       "475       12.830         15.73           82.89      506.9          0.09040   \n",
       "206        9.876         17.27           62.92      295.4          0.10890   \n",
       "416        9.405         21.70           59.60      271.2          0.10440   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "33            0.17190         0.16570              0.07593         0.1853   \n",
       "22            0.21350         0.20770              0.09756         0.2521   \n",
       "124           0.07325         0.08092              0.02800         0.1422   \n",
       "418           0.05794         0.02360              0.02402         0.1583   \n",
       "..                ...             ...                  ...            ...   \n",
       "342           0.09097         0.05397              0.03341         0.1776   \n",
       "455           0.07426         0.02819              0.03264         0.1375   \n",
       "475           0.08269         0.05835              0.03078         0.1705   \n",
       "206           0.07232         0.01756              0.01952         0.1934   \n",
       "416           0.06159         0.02047              0.01257         0.2025   \n",
       "\n",
       "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
       "565                 0.05533  ...         23.69          38.25   \n",
       "33                  0.06261  ...         24.15          30.90   \n",
       "22                  0.07032  ...         18.07          19.08   \n",
       "124                 0.05823  ...         14.26          22.75   \n",
       "418                 0.06275  ...         13.65          16.92   \n",
       "..                      ...  ...           ...            ...   \n",
       "342                 0.06907  ...         11.92          19.90   \n",
       "455                 0.06016  ...         15.05          41.61   \n",
       "475                 0.05913  ...         14.09          19.35   \n",
       "206                 0.06285  ...         10.42          23.22   \n",
       "416                 0.06601  ...         10.85          31.24   \n",
       "\n",
       "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "565           155.00      1731.0            0.1166             0.1922   \n",
       "33            161.40      1813.0            0.1509             0.6590   \n",
       "22            125.10       980.9            0.1390             0.5954   \n",
       "124            91.99       632.1            0.1025             0.2531   \n",
       "418            88.12       566.9            0.1314             0.1607   \n",
       "..               ...         ...               ...                ...   \n",
       "342            79.76       440.0            0.1418             0.2210   \n",
       "455            96.69       705.6            0.1172             0.1421   \n",
       "475            93.22       605.8            0.1326             0.2610   \n",
       "206            67.08       331.6            0.1415             0.1247   \n",
       "416            68.73       359.4            0.1526             0.1193   \n",
       "\n",
       "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "565          0.32150               0.16280          0.2572   \n",
       "33           0.60910               0.17850          0.3672   \n",
       "22           0.63050               0.23930          0.4667   \n",
       "124          0.33080               0.08978          0.2048   \n",
       "418          0.09385               0.08224          0.2775   \n",
       "..               ...                   ...             ...   \n",
       "342          0.22990               0.10750          0.3301   \n",
       "455          0.07003               0.07763          0.2196   \n",
       "475          0.34760               0.09783          0.3006   \n",
       "206          0.06213               0.05588          0.2989   \n",
       "416          0.06141               0.03770          0.2872   \n",
       "\n",
       "     fractal_dimension_worst  \n",
       "565                  0.06637  \n",
       "33                   0.11230  \n",
       "22                   0.09946  \n",
       "124                  0.07628  \n",
       "418                  0.09464  \n",
       "..                       ...  \n",
       "342                  0.09080  \n",
       "455                  0.07675  \n",
       "475                  0.07802  \n",
       "206                  0.07380  \n",
       "416                  0.08304  \n",
       "\n",
       "[455 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b88a2a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "565    M\n",
       "33     M\n",
       "22     M\n",
       "124    B\n",
       "418    B\n",
       "      ..\n",
       "342    B\n",
       "455    B\n",
       "475    B\n",
       "206    B\n",
       "416    B\n",
       "Name: diagnosis, Length: 455, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c16eead",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f668b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59a052dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = torch.from_numpy(X_train)\n",
    "X_test_tensor = torch.from_numpy(X_test)\n",
    "y_train_tensor = torch.from_numpy(y_train)\n",
    "y_test_tensor = torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9566ae46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([455, 30])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7f03c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([455])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb3cf75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN():\n",
    "    def __init__(self,X):\n",
    "        self.weights = torch.rand(X.shape[1],1,dtype=torch.float64,requires_grad=True)\n",
    "        self.bias = torch.zeros(1,dtype=torch.float64,requires_grad=True)\n",
    "    def forward(self,X):\n",
    "        z = torch.matmul(X,self.weights) + self.bias\n",
    "        y_pred = torch.sigmoid(z)\n",
    "        return y_pred\n",
    "    def loss_function(self,y_pred,y_true):\n",
    "        epsilon = 1e-7\n",
    "        y_pred = torch.clamp(y_pred,epsilon,1-epsilon)\n",
    "        loss = -(y_true*torch.log(y_pred) + (1-y_true)*torch.log(1-y_pred)).mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba8b1240",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a97d873d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 , loss : 4.20566892851779\n",
      "Epoch : 2 , loss : 4.109392110893031\n",
      "Epoch : 3 , loss : 4.009047463833717\n",
      "Epoch : 4 , loss : 3.9055986522814194\n",
      "Epoch : 5 , loss : 3.7977019187467356\n",
      "Epoch : 6 , loss : 3.680851920860385\n",
      "Epoch : 7 , loss : 3.560023531861911\n",
      "Epoch : 8 , loss : 3.4349518149210287\n",
      "Epoch : 9 , loss : 3.3067771063544886\n",
      "Epoch : 10 , loss : 3.1792919415750225\n",
      "Epoch : 11 , loss : 3.0513251354044133\n",
      "Epoch : 12 , loss : 2.921263232396309\n",
      "Epoch : 13 , loss : 2.7857673849219164\n",
      "Epoch : 14 , loss : 2.650363295576583\n",
      "Epoch : 15 , loss : 2.5099945285395124\n",
      "Epoch : 16 , loss : 2.3708018765089296\n",
      "Epoch : 17 , loss : 2.231080750255072\n",
      "Epoch : 18 , loss : 2.089247163465636\n",
      "Epoch : 19 , loss : 1.9496825254926946\n",
      "Epoch : 20 , loss : 1.8167234122665847\n",
      "Epoch : 21 , loss : 1.6895247473932575\n",
      "Epoch : 22 , loss : 1.5716327051629388\n",
      "Epoch : 23 , loss : 1.461218597311668\n",
      "Epoch : 24 , loss : 1.3603167510414138\n",
      "Epoch : 25 , loss : 1.2717890343713572\n",
      "Epoch : 26 , loss : 1.1954126864571373\n",
      "Epoch : 27 , loss : 1.1305098625917458\n",
      "Epoch : 28 , loss : 1.076043364612774\n",
      "Epoch : 29 , loss : 1.030738708629944\n",
      "Epoch : 30 , loss : 0.9932085247034034\n",
      "Epoch : 31 , loss : 0.9620678624359151\n",
      "Epoch : 32 , loss : 0.9360358760417007\n",
      "Epoch : 33 , loss : 0.9140098791226549\n",
      "Epoch : 34 , loss : 0.8950972983425052\n",
      "Epoch : 35 , loss : 0.8786099859624148\n",
      "Epoch : 36 , loss : 0.8640356346210769\n",
      "Epoch : 37 , loss : 0.8510001582329916\n",
      "Epoch : 38 , loss : 0.8392312016288546\n",
      "Epoch : 39 , loss : 0.8285281470191551\n",
      "Epoch : 40 , loss : 0.8187398554288964\n",
      "Epoch : 41 , loss : 0.8097491571317327\n",
      "Epoch : 42 , loss : 0.8014624431480448\n",
      "Epoch : 43 , loss : 0.7938028184929272\n",
      "Epoch : 44 , loss : 0.7867056261180525\n",
      "Epoch : 45 , loss : 0.7801155014301387\n",
      "Epoch : 46 , loss : 0.7739843962828238\n",
      "Epoch : 47 , loss : 0.7682702111098011\n",
      "Epoch : 48 , loss : 0.762935808621239\n",
      "Epoch : 49 , loss : 0.7579482698246569\n",
      "Epoch : 50 , loss : 0.7532783080533142\n",
      "Epoch : 51 , loss : 0.7488997903660751\n",
      "Epoch : 52 , loss : 0.7447893358846266\n",
      "Epoch : 53 , loss : 0.7409259725094717\n",
      "Epoch : 54 , loss : 0.7372908403132526\n",
      "Epoch : 55 , loss : 0.7338669338147324\n",
      "Epoch : 56 , loss : 0.7306388775476952\n",
      "Epoch : 57 , loss : 0.7275927306041923\n",
      "Epoch : 58 , loss : 0.7247158165841908\n",
      "Epoch : 59 , loss : 0.7219965758675015\n",
      "Epoch : 60 , loss : 0.7194244374712315\n",
      "Epoch : 61 , loss : 0.7169897080357811\n",
      "Epoch : 62 , loss : 0.7146834757281638\n",
      "Epoch : 63 , loss : 0.7124975270782028\n",
      "Epoch : 64 , loss : 0.7104242749765364\n",
      "Epoch : 65 , loss : 0.7084566962646042\n",
      "Epoch : 66 , loss : 0.7065882775354534\n",
      "Epoch : 67 , loss : 0.7048129679393431\n",
      "Epoch : 68 , loss : 0.7031251379489527\n",
      "Epoch : 69 , loss : 0.7015195431850004\n",
      "Epoch : 70 , loss : 0.6999912925341397\n",
      "Epoch : 71 , loss : 0.6985358199073429\n",
      "Epoch : 72 , loss : 0.6971488590891329\n",
      "Epoch : 73 , loss : 0.6958264212167554\n",
      "Epoch : 74 , loss : 0.6945647745046557\n",
      "Epoch : 75 , loss : 0.6933604258945275\n",
      "Epoch : 76 , loss : 0.6922101043658855\n",
      "Epoch : 77 , loss : 0.6911107456877847\n",
      "Epoch : 78 , loss : 0.6900594784301111\n",
      "Epoch : 79 , loss : 0.6890536110839305\n",
      "Epoch : 80 , loss : 0.6880906201657415\n",
      "Epoch : 81 , loss : 0.6871681392010406\n",
      "Epoch : 82 , loss : 0.6862839484992557\n",
      "Epoch : 83 , loss : 0.6854359656455024\n",
      "Epoch : 84 , loss : 0.6846222366454268\n",
      "Epoch : 85 , loss : 0.6838409276681123\n",
      "Epoch : 86 , loss : 0.683090317339079\n",
      "Epoch : 87 , loss : 0.6823687895411362\n",
      "Epoch : 88 , loss : 0.681674826685561\n",
      "Epoch : 89 , loss : 0.6810070034199532\n",
      "Epoch : 90 , loss : 0.6803639807423758\n",
      "Epoch : 91 , loss : 0.6797445004941396\n",
      "Epoch : 92 , loss : 0.6791473802059443\n",
      "Epoch : 93 , loss : 0.6785715082741285\n",
      "Epoch : 94 , loss : 0.6780158394455729\n",
      "Epoch : 95 , loss : 0.6774793905913811\n",
      "Epoch : 96 , loss : 0.6769612367508805\n",
      "Epoch : 97 , loss : 0.6764605074287656\n",
      "Epoch : 98 , loss : 0.6759763831293577\n",
      "Epoch : 99 , loss : 0.6755080921130214\n",
      "Epoch : 100 , loss : 0.6750549073607446\n",
      "Epoch : 101 , loss : 0.6746161437337841\n",
      "Epoch : 102 , loss : 0.6741911553161087\n",
      "Epoch : 103 , loss : 0.6737793329281385\n",
      "Epoch : 104 , loss : 0.6733801018009898\n",
      "Epoch : 105 , loss : 0.6729929194011072\n",
      "Epoch : 106 , loss : 0.6726172733957787\n",
      "Epoch : 107 , loss : 0.6722526797506146\n",
      "Epoch : 108 , loss : 0.6718986809506154\n",
      "Epoch : 109 , loss : 0.6715548443369608\n",
      "Epoch : 110 , loss : 0.6712207605521378\n",
      "Epoch : 111 , loss : 0.6708960420864674\n",
      "Epoch : 112 , loss : 0.6705803219195223\n",
      "Epoch : 113 , loss : 0.6702732522503185\n",
      "Epoch : 114 , loss : 0.6699745033105455\n",
      "Epoch : 115 , loss : 0.6696837622554477\n",
      "Epoch : 116 , loss : 0.669400732127308\n",
      "Epoch : 117 , loss : 0.669125130886793\n",
      "Epoch : 118 , loss : 0.6688566905077189\n",
      "Epoch : 119 , loss : 0.6685951561310722\n",
      "Epoch : 120 , loss : 0.6683402852743859\n",
      "Epoch : 121 , loss : 0.6680918470928132\n",
      "Epoch : 122 , loss : 0.667849621688479\n",
      "Epoch : 123 , loss : 0.667613399464902\n",
      "Epoch : 124 , loss : 0.6673829805234944\n",
      "Epoch : 125 , loss : 0.6671581740993309\n",
      "Epoch : 126 , loss : 0.6669387980335648\n",
      "Epoch : 127 , loss : 0.6667246782800431\n",
      "Epoch : 128 , loss : 0.6665156484438265\n",
      "Epoch : 129 , loss : 0.6663115493494756\n",
      "Epoch : 130 , loss : 0.666112228637104\n",
      "Epoch : 131 , loss : 0.6659175403843322\n",
      "Epoch : 132 , loss : 0.6657273447524007\n",
      "Epoch : 133 , loss : 0.6655415076548182\n",
      "Epoch : 134 , loss : 0.6653599004470224\n",
      "Epoch : 135 , loss : 0.6651823996356483\n",
      "Epoch : 136 , loss : 0.6650088866060767\n",
      "Epoch : 137 , loss : 0.664839247367038\n",
      "Epoch : 138 , loss : 0.6646733723111221\n",
      "Epoch : 139 , loss : 0.6645111559901292\n",
      "Epoch : 140 , loss : 0.6643524969042621\n",
      "Epoch : 141 , loss : 0.6641972973042355\n",
      "Epoch : 142 , loss : 0.6640454630054379\n",
      "Epoch : 143 , loss : 0.6638969032133397\n",
      "Epoch : 144 , loss : 0.6637515303593979\n",
      "Epoch : 145 , loss : 0.6636092599467628\n",
      "Epoch : 146 , loss : 0.6634700104051303\n",
      "Epoch : 147 , loss : 0.6633337029541415\n",
      "Epoch : 148 , loss : 0.6632002614747591\n",
      "Epoch : 149 , loss : 0.6630696123881009\n",
      "Epoch : 150 , loss : 0.662941684541239\n",
      "Epoch : 151 , loss : 0.6628164090995099\n",
      "Epoch : 152 , loss : 0.6626937194449117\n",
      "Epoch : 153 , loss : 0.6625735510801949\n",
      "Epoch : 154 , loss : 0.6624558415382774\n",
      "Epoch : 155 , loss : 0.6623405302966431\n",
      "Epoch : 156 , loss : 0.6622275586964044\n",
      "Epoch : 157 , loss : 0.6621168698657314\n",
      "Epoch : 158 , loss : 0.6620084086473733\n",
      "Epoch : 159 , loss : 0.6619021215300095\n",
      "Epoch : 160 , loss : 0.6617979565831978\n",
      "Epoch : 161 , loss : 0.6616958633956879\n",
      "Epoch : 162 , loss : 0.6615957930168963\n",
      "Epoch : 163 , loss : 0.6614976979013486\n",
      "Epoch : 164 , loss : 0.6614015318559039\n",
      "Epoch : 165 , loss : 0.6613072499895966\n",
      "Epoch : 166 , loss : 0.6612148086659345\n",
      "Epoch : 167 , loss : 0.6611241654575092\n",
      "Epoch : 168 , loss : 0.6610352791027773\n",
      "Epoch : 169 , loss : 0.6609481094648888\n",
      "Epoch : 170 , loss : 0.6608626174924395\n",
      "Epoch : 171 , loss : 0.6607787651820364\n",
      "Epoch : 172 , loss : 0.660696515542574\n",
      "Epoch : 173 , loss : 0.6606158325611203\n",
      "Epoch : 174 , loss : 0.6605366811703224\n",
      "Epoch : 175 , loss : 0.6604590272172486\n",
      "Epoch : 176 , loss : 0.6603828374335847\n",
      "Epoch : 177 , loss : 0.6603080794071098\n",
      "Epoch : 178 , loss : 0.6602347215543826\n",
      "Epoch : 179 , loss : 0.6601627330945739\n",
      "Epoch : 180 , loss : 0.6600920840243804\n",
      "Epoch : 181 , loss : 0.6600227450939659\n",
      "Epoch : 182 , loss : 0.6599546877838741\n",
      "Epoch : 183 , loss : 0.6598878842828635\n",
      "Epoch : 184 , loss : 0.6598223074666155\n",
      "Epoch : 185 , loss : 0.6597579308772717\n",
      "Epoch : 186 , loss : 0.6596947287037614\n",
      "Epoch : 187 , loss : 0.6596326757628749\n",
      "Epoch : 188 , loss : 0.659571747481049\n",
      "Epoch : 189 , loss : 0.6595119198768304\n",
      "Epoch : 190 , loss : 0.6594531695439829\n",
      "Epoch : 191 , loss : 0.6593954736352069\n",
      "Epoch : 192 , loss : 0.6593388098464447\n",
      "Epoch : 193 , loss : 0.6592831564017424\n",
      "Epoch : 194 , loss : 0.6592284920386432\n",
      "Epoch : 195 , loss : 0.6591747959940889\n",
      "Epoch : 196 , loss : 0.6591220479908044\n",
      "Epoch : 197 , loss : 0.659070228224145\n",
      "Epoch : 198 , loss : 0.6590193173493878\n",
      "Epoch : 199 , loss : 0.658969296469445\n",
      "Epoch : 200 , loss : 0.65892014712298\n",
      "Epoch : 201 , loss : 0.658871851272916\n",
      "Epoch : 202 , loss : 0.6588243912953113\n",
      "Epoch : 203 , loss : 0.6587777499685921\n",
      "Epoch : 204 , loss : 0.6587319104631273\n",
      "Epoch : 205 , loss : 0.658686856331129\n",
      "Epoch : 206 , loss : 0.6586425714968686\n",
      "Epoch : 207 , loss : 0.658599040247193\n",
      "Epoch : 208 , loss : 0.6585562472223319\n",
      "Epoch : 209 , loss : 0.6585141774069834\n",
      "Epoch : 210 , loss : 0.6584728161216663\n",
      "Epoch : 211 , loss : 0.6584321490143303\n",
      "Epoch : 212 , loss : 0.658392162052216\n",
      "Epoch : 213 , loss : 0.6583528415139506\n",
      "Epoch : 214 , loss : 0.6583141739818751\n",
      "Epoch : 215 , loss : 0.6582761463345931\n",
      "Epoch : 216 , loss : 0.6582387457397324\n",
      "Epoch : 217 , loss : 0.6582019596469126\n",
      "Epoch : 218 , loss : 0.6581657757809122\n",
      "Epoch : 219 , loss : 0.658130182135025\n",
      "Epoch : 220 , loss : 0.6580951669646049\n",
      "Epoch : 221 , loss : 0.6580607187807863\n",
      "Epoch : 222 , loss : 0.6580268263443783\n",
      "Epoch : 223 , loss : 0.6579934786599263\n",
      "Epoch : 224 , loss : 0.6579606649699339\n",
      "Epoch : 225 , loss : 0.657928374749241\n",
      "Epoch : 226 , loss : 0.6578965976995523\n",
      "Epoch : 227 , loss : 0.6578653237441128\n",
      "Epoch : 228 , loss : 0.6578345430225235\n",
      "Epoch : 229 , loss : 0.657804245885694\n",
      "Epoch : 230 , loss : 0.6577744228909277\n",
      "Epoch : 231 , loss : 0.6577450647971358\n",
      "Epoch : 232 , loss : 0.6577161625601744\n",
      "Epoch : 233 , loss : 0.6576877073283024\n",
      "Epoch : 234 , loss : 0.6576596904377575\n",
      "Epoch : 235 , loss : 0.6576321034084431\n",
      "Epoch : 236 , loss : 0.6576049379397276\n",
      "Epoch : 237 , loss : 0.6575781859063474\n",
      "Epoch : 238 , loss : 0.6575518393544166\n",
      "Epoch : 239 , loss : 0.6575258904975331\n",
      "Epoch : 240 , loss : 0.6575003317129866\n",
      "Epoch : 241 , loss : 0.657475155538057\n",
      "Epoch : 242 , loss : 0.6574503546664079\n",
      "Epoch : 243 , loss : 0.6574259219445665\n",
      "Epoch : 244 , loss : 0.6574018503684931\n",
      "Epoch : 245 , loss : 0.657378133080232\n",
      "Epoch : 246 , loss : 0.6573547633646475\n",
      "Epoch : 247 , loss : 0.6573317346462354\n",
      "Epoch : 248 , loss : 0.6573090404860159\n",
      "Epoch : 249 , loss : 0.6572866745784989\n",
      "Epoch : 250 , loss : 0.6572646307487247\n",
      "Epoch : 251 , loss : 0.6572429029493735\n",
      "Epoch : 252 , loss : 0.6572214852579462\n",
      "Epoch : 253 , loss : 0.6572003718740117\n",
      "Epoch : 254 , loss : 0.6571795571165199\n",
      "Epoch : 255 , loss : 0.657159035421178\n",
      "Epoch : 256 , loss : 0.6571388013378907\n",
      "Epoch : 257 , loss : 0.6571188495282584\n",
      "Epoch : 258 , loss : 0.6570991747631362\n",
      "Epoch : 259 , loss : 0.6570797719202496\n",
      "Epoch : 260 , loss : 0.6570606359818658\n",
      "Epoch : 261 , loss : 0.6570417620325203\n",
      "Epoch : 262 , loss : 0.6570231452567952\n",
      "Epoch : 263 , loss : 0.6570047809371509\n",
      "Epoch : 264 , loss : 0.6569866644518054\n",
      "Epoch : 265 , loss : 0.6569687912726667\n",
      "Epoch : 266 , loss : 0.6569511569633086\n",
      "Epoch : 267 , loss : 0.6569337571769961\n",
      "Epoch : 268 , loss : 0.6569165876547548\n",
      "Epoch : 269 , loss : 0.6568996442234859\n",
      "Epoch : 270 , loss : 0.6568829227941223\n",
      "Epoch : 271 , loss : 0.6568664193598291\n",
      "Epoch : 272 , loss : 0.6568501299942434\n",
      "Epoch : 273 , loss : 0.656834050849754\n",
      "Epoch : 274 , loss : 0.6568181781558231\n",
      "Epoch : 275 , loss : 0.6568025082173414\n",
      "Epoch : 276 , loss : 0.6567870374130245\n",
      "Epoch : 277 , loss : 0.6567717621938431\n",
      "Epoch : 278 , loss : 0.6567566790814892\n",
      "Epoch : 279 , loss : 0.656741784666878\n",
      "Epoch : 280 , loss : 0.6567270756086805\n",
      "Epoch : 281 , loss : 0.6567125486318928\n",
      "Epoch : 282 , loss : 0.6566982005264336\n",
      "Epoch : 283 , loss : 0.6566840281457765\n",
      "Epoch : 284 , loss : 0.6566700284056104\n",
      "Epoch : 285 , loss : 0.6566561982825304\n",
      "Epoch : 286 , loss : 0.6566425348127579\n",
      "Epoch : 287 , loss : 0.6566290350908894\n",
      "Epoch : 288 , loss : 0.656615696268673\n",
      "Epoch : 289 , loss : 0.6566025155538108\n",
      "Epoch : 290 , loss : 0.6565894902087894\n",
      "Epoch : 291 , loss : 0.6565766175497354\n",
      "Epoch : 292 , loss : 0.6565638949452957\n",
      "Epoch : 293 , loss : 0.6565513198155434\n",
      "Epoch : 294 , loss : 0.656538889630907\n",
      "Epoch : 295 , loss : 0.6565266019111236\n",
      "Epoch : 296 , loss : 0.656514454224214\n",
      "Epoch : 297 , loss : 0.656502444185482\n",
      "Epoch : 298 , loss : 0.656490569456534\n",
      "Epoch : 299 , loss : 0.6564788277443198\n",
      "Epoch : 300 , loss : 0.6564672168001966\n",
      "Epoch : 301 , loss : 0.6564557344190106\n",
      "Epoch : 302 , loss : 0.6564443784382\n",
      "Epoch : 303 , loss : 0.6564331467369175\n",
      "Epoch : 304 , loss : 0.6564220372351708\n",
      "Epoch : 305 , loss : 0.6564110478929832\n",
      "Epoch : 306 , loss : 0.6564001767095716\n",
      "Epoch : 307 , loss : 0.6563894217225416\n",
      "Epoch : 308 , loss : 0.6563787810071007\n",
      "Epoch : 309 , loss : 0.6563682526752891\n",
      "Epoch : 310 , loss : 0.6563578348752256\n",
      "Epoch : 311 , loss : 0.6563475257903706\n",
      "Epoch : 312 , loss : 0.6563373236388048\n",
      "Epoch : 313 , loss : 0.6563272266725231\n",
      "Epoch : 314 , loss : 0.6563172331767442\n",
      "Epoch : 315 , loss : 0.6563073414692343\n",
      "Epoch : 316 , loss : 0.6562975498996457\n",
      "Epoch : 317 , loss : 0.6562878568488695\n",
      "Epoch : 318 , loss : 0.6562782607284017\n",
      "Epoch : 319 , loss : 0.6562687599797232\n",
      "Epoch : 320 , loss : 0.6562593530736933\n",
      "Epoch : 321 , loss : 0.6562500385099547\n",
      "Epoch : 322 , loss : 0.6562408148163533\n",
      "Epoch : 323 , loss : 0.6562316805483681\n",
      "Epoch : 324 , loss : 0.6562226342885559\n",
      "Epoch : 325 , loss : 0.656213674646003\n",
      "Epoch : 326 , loss : 0.6562048002557951\n",
      "Epoch : 327 , loss : 0.6561960097784924\n",
      "Epoch : 328 , loss : 0.6561873018996189\n",
      "Epoch : 329 , loss : 0.6561786753291625\n",
      "Epoch : 330 , loss : 0.6561701288010842\n",
      "Epoch : 331 , loss : 0.6561616610728386\n",
      "Epoch : 332 , loss : 0.6561532709249039\n",
      "Epoch : 333 , loss : 0.6561449571603232\n",
      "Epoch : 334 , loss : 0.6561367186042525\n",
      "Epoch : 335 , loss : 0.6561285541035222\n",
      "Epoch : 336 , loss : 0.656120462526204\n",
      "Epoch : 337 , loss : 0.6561124427611891\n",
      "Epoch : 338 , loss : 0.656104493717774\n",
      "Epoch : 339 , loss : 0.6560966143252567\n",
      "Epoch : 340 , loss : 0.6560888035325392\n",
      "Epoch : 341 , loss : 0.6560810603077393\n",
      "Epoch : 342 , loss : 0.6560733836378102\n",
      "Epoch : 343 , loss : 0.6560657725281698\n",
      "Epoch : 344 , loss : 0.6560582260023337\n",
      "Epoch : 345 , loss : 0.6560507431015601\n",
      "Epoch : 346 , loss : 0.6560433228844994\n",
      "Epoch : 347 , loss : 0.6560359644268522\n",
      "Epoch : 348 , loss : 0.6560286668210339\n",
      "Epoch : 349 , loss : 0.6560214291758463\n",
      "Epoch : 350 , loss : 0.6560142506161563\n",
      "Epoch : 351 , loss : 0.6560071302825812\n",
      "Epoch : 352 , loss : 0.6560000673311797\n",
      "Epoch : 353 , loss : 0.65599306093315\n",
      "Epoch : 354 , loss : 0.6559861102745346\n",
      "Epoch : 355 , loss : 0.6559792145559301\n",
      "Epoch : 356 , loss : 0.6559723729922035\n",
      "Epoch : 357 , loss : 0.6559655848122141\n",
      "Epoch : 358 , loss : 0.6559588492585413\n",
      "Epoch : 359 , loss : 0.6559521655872181\n",
      "Epoch : 360 , loss : 0.6559455330674703\n",
      "Epoch : 361 , loss : 0.6559389509814594\n",
      "Epoch : 362 , loss : 0.6559324186240331\n",
      "Epoch : 363 , loss : 0.6559259353024796\n",
      "Epoch : 364 , loss : 0.6559195003362862\n",
      "Epoch : 365 , loss : 0.6559131130569057\n",
      "Epoch : 366 , loss : 0.6559067728075229\n",
      "Epoch : 367 , loss : 0.6559004789428308\n",
      "Epoch : 368 , loss : 0.6558942308288079\n",
      "Epoch : 369 , loss : 0.6558880278425014\n",
      "Epoch : 370 , loss : 0.6558818693718151\n",
      "Epoch : 371 , loss : 0.6558757548153002\n",
      "Epoch : 372 , loss : 0.6558696835819519\n",
      "Epoch : 373 , loss : 0.6558636550910091\n",
      "Epoch : 374 , loss : 0.6558576687717591\n",
      "Epoch : 375 , loss : 0.655851724063345\n",
      "Epoch : 376 , loss : 0.6558458204145776\n",
      "Epoch : 377 , loss : 0.6558399572837519\n",
      "Epoch : 378 , loss : 0.6558341341384653\n",
      "Epoch : 379 , loss : 0.6558283504554424\n",
      "Epoch : 380 , loss : 0.6558226057203593\n",
      "Epoch : 381 , loss : 0.6558168994276767\n",
      "Epoch : 382 , loss : 0.6558112310804701\n",
      "Epoch : 383 , loss : 0.6558056001902695\n",
      "Epoch : 384 , loss : 0.6558000062768978\n",
      "Epoch : 385 , loss : 0.6557944488683148\n",
      "Epoch : 386 , loss : 0.6557889275004638\n",
      "Epoch : 387 , loss : 0.6557834417171207\n",
      "Epoch : 388 , loss : 0.6557779910697468\n",
      "Epoch : 389 , loss : 0.6557725751173442\n",
      "Epoch : 390 , loss : 0.6557671934263144\n",
      "Epoch : 391 , loss : 0.6557618455703191\n",
      "Epoch : 392 , loss : 0.6557565311301445\n",
      "Epoch : 393 , loss : 0.6557512496935677\n",
      "Epoch : 394 , loss : 0.6557460008552263\n",
      "Epoch : 395 , loss : 0.6557407842164897\n",
      "Epoch : 396 , loss : 0.6557355993853345\n",
      "Epoch : 397 , loss : 0.6557304459762205\n",
      "Epoch : 398 , loss : 0.6557253236099705\n",
      "Epoch : 399 , loss : 0.6557202319136521\n",
      "Epoch : 400 , loss : 0.6557151705204618\n",
      "Epoch : 401 , loss : 0.6557101390696106\n",
      "Epoch : 402 , loss : 0.655705137206214\n",
      "Epoch : 403 , loss : 0.6557001645811817\n",
      "Epoch : 404 , loss : 0.6556952208511111\n",
      "Epoch : 405 , loss : 0.655690305678182\n",
      "Epoch : 406 , loss : 0.6556854187300538\n",
      "Epoch : 407 , loss : 0.6556805596797651\n",
      "Epoch : 408 , loss : 0.655675728205634\n",
      "Epoch : 409 , loss : 0.6556709239911621\n",
      "Epoch : 410 , loss : 0.655666146724939\n",
      "Epoch : 411 , loss : 0.6556613961005482\n",
      "Epoch : 412 , loss : 0.6556566718164782\n",
      "Epoch : 413 , loss : 0.6556519735760299\n",
      "Epoch : 414 , loss : 0.6556473010872307\n",
      "Epoch : 415 , loss : 0.6556426540627482\n",
      "Epoch : 416 , loss : 0.6556380322198053\n",
      "Epoch : 417 , loss : 0.6556334352800977\n",
      "Epoch : 418 , loss : 0.6556288629697118\n",
      "Epoch : 419 , loss : 0.6556243150190469\n",
      "Epoch : 420 , loss : 0.6556197911627355\n",
      "Epoch : 421 , loss : 0.6556152911395676\n",
      "Epoch : 422 , loss : 0.6556108146924149\n",
      "Epoch : 423 , loss : 0.655606361568158\n",
      "Epoch : 424 , loss : 0.6556019315176137\n",
      "Epoch : 425 , loss : 0.6555975242954645\n",
      "Epoch : 426 , loss : 0.6555931396601885\n",
      "Epoch : 427 , loss : 0.6555887773739925\n",
      "Epoch : 428 , loss : 0.6555844372027438\n",
      "Epoch : 429 , loss : 0.6555801189159058\n",
      "Epoch : 430 , loss : 0.6555758222864732\n",
      "Epoch : 431 , loss : 0.6555715470909087\n",
      "Epoch : 432 , loss : 0.6555672931090826\n",
      "Epoch : 433 , loss : 0.6555630601242102\n",
      "Epoch : 434 , loss : 0.6555588479227935\n",
      "Epoch : 435 , loss : 0.6555546562945632\n",
      "Epoch : 436 , loss : 0.6555504850324207\n",
      "Epoch : 437 , loss : 0.6555463339323824\n",
      "Epoch : 438 , loss : 0.655542202793524\n",
      "Epoch : 439 , loss : 0.6555380914179275\n",
      "Epoch : 440 , loss : 0.6555339996106279\n",
      "Epoch : 441 , loss : 0.6555299271795607\n",
      "Epoch : 442 , loss : 0.6555258739355113\n",
      "Epoch : 443 , loss : 0.6555218396920657\n",
      "Epoch : 444 , loss : 0.6555178242655595\n",
      "Epoch : 445 , loss : 0.6555138274750324\n",
      "Epoch : 446 , loss : 0.6555098491421786\n",
      "Epoch : 447 , loss : 0.6555058890913018\n",
      "Epoch : 448 , loss : 0.6555019471492695\n",
      "Epoch : 449 , loss : 0.655498023145468\n",
      "Epoch : 450 , loss : 0.6554941169117596\n",
      "Epoch : 451 , loss : 0.6554902282824383\n",
      "Epoch : 452 , loss : 0.6554863570941887\n",
      "Epoch : 453 , loss : 0.6554825031860446\n",
      "Epoch : 454 , loss : 0.6554786663993477\n",
      "Epoch : 455 , loss : 0.6554748465777087\n",
      "Epoch : 456 , loss : 0.6554710435669681\n",
      "Epoch : 457 , loss : 0.6554672572151569\n",
      "Epoch : 458 , loss : 0.6554634873724604\n",
      "Epoch : 459 , loss : 0.6554597338911806\n",
      "Epoch : 460 , loss : 0.6554559966256992\n",
      "Epoch : 461 , loss : 0.6554522754324443\n",
      "Epoch : 462 , loss : 0.655448570169853\n",
      "Epoch : 463 , loss : 0.655444880698339\n",
      "Epoch : 464 , loss : 0.6554412068802574\n",
      "Epoch : 465 , loss : 0.6554375485798735\n",
      "Epoch : 466 , loss : 0.6554339056633293\n",
      "Epoch : 467 , loss : 0.655430277998612\n",
      "Epoch : 468 , loss : 0.6554266654555229\n",
      "Epoch : 469 , loss : 0.6554230679056464\n",
      "Epoch : 470 , loss : 0.655419485222321\n",
      "Epoch : 471 , loss : 0.6554159172806088\n",
      "Epoch : 472 , loss : 0.6554123639572667\n",
      "Epoch : 473 , loss : 0.6554088251307184\n",
      "Epoch : 474 , loss : 0.6554053006810265\n",
      "Epoch : 475 , loss : 0.6554017904898651\n",
      "Epoch : 476 , loss : 0.6553982944404926\n",
      "Epoch : 477 , loss : 0.6553948124177252\n",
      "Epoch : 478 , loss : 0.6553913443079125\n",
      "Epoch : 479 , loss : 0.6553878899989092\n",
      "Epoch : 480 , loss : 0.6553844493800535\n",
      "Epoch : 481 , loss : 0.6553810223421405\n",
      "Epoch : 482 , loss : 0.6553776087773983\n",
      "Epoch : 483 , loss : 0.6553742085794653\n",
      "Epoch : 484 , loss : 0.6553708216433661\n",
      "Epoch : 485 , loss : 0.6553674478654893\n",
      "Epoch : 486 , loss : 0.6553640871435651\n",
      "Epoch : 487 , loss : 0.6553607393766427\n",
      "Epoch : 488 , loss : 0.65535740446507\n",
      "Epoch : 489 , loss : 0.6553540823104712\n",
      "Epoch : 490 , loss : 0.655350772815727\n",
      "Epoch : 491 , loss : 0.6553474758849529\n",
      "Epoch : 492 , loss : 0.6553441914234815\n",
      "Epoch : 493 , loss : 0.6553409193378403\n",
      "Epoch : 494 , loss : 0.6553376595357336\n",
      "Epoch : 495 , loss : 0.6553344119260236\n",
      "Epoch : 496 , loss : 0.6553311764187113\n",
      "Epoch : 497 , loss : 0.6553279529249191\n",
      "Epoch : 498 , loss : 0.6553247413568714\n",
      "Epoch : 499 , loss : 0.6553215416278783\n",
      "Epoch : 500 , loss : 0.6553183536523176\n",
      "Epoch : 501 , loss : 0.6553151773456178\n",
      "Epoch : 502 , loss : 0.655312012624242\n",
      "Epoch : 503 , loss : 0.6553088594056703\n",
      "Epoch : 504 , loss : 0.6553057176083847\n",
      "Epoch : 505 , loss : 0.6553025871518531\n",
      "Epoch : 506 , loss : 0.6552994679565133\n",
      "Epoch : 507 , loss : 0.655296359943758\n",
      "Epoch : 508 , loss : 0.65529326303592\n",
      "Epoch : 509 , loss : 0.6552901771562569\n",
      "Epoch : 510 , loss : 0.655287102228937\n",
      "Epoch : 511 , loss : 0.6552840381790256\n",
      "Epoch : 512 , loss : 0.6552809849324694\n",
      "Epoch : 513 , loss : 0.6552779424160847\n",
      "Epoch : 514 , loss : 0.6552749105575426\n",
      "Epoch : 515 , loss : 0.655271889285356\n",
      "Epoch : 516 , loss : 0.6552688785288672\n",
      "Epoch : 517 , loss : 0.6552658782182341\n",
      "Epoch : 518 , loss : 0.6552628882844184\n",
      "Epoch : 519 , loss : 0.655259908659173\n",
      "Epoch : 520 , loss : 0.65525693927503\n",
      "Epoch : 521 , loss : 0.6552539800652883\n",
      "Epoch : 522 , loss : 0.6552510309640027\n",
      "Epoch : 523 , loss : 0.6552480919059717\n",
      "Epoch : 524 , loss : 0.6552451628267256\n",
      "Epoch : 525 , loss : 0.6552422436625178\n",
      "Epoch : 526 , loss : 0.6552393343503106\n",
      "Epoch : 527 , loss : 0.6552364348277674\n",
      "Epoch : 528 , loss : 0.6552335450332403\n",
      "Epoch : 529 , loss : 0.65523066490576\n",
      "Epoch : 530 , loss : 0.6552277943850267\n",
      "Epoch : 531 , loss : 0.6552249334113981\n",
      "Epoch : 532 , loss : 0.6552220819258822\n",
      "Epoch : 533 , loss : 0.6552192398701248\n",
      "Epoch : 534 , loss : 0.6552164071864024\n",
      "Epoch : 535 , loss : 0.6552135838176114\n",
      "Epoch : 536 , loss : 0.655210769707259\n",
      "Epoch : 537 , loss : 0.6552079647994551\n",
      "Epoch : 538 , loss : 0.6552051690389027\n",
      "Epoch : 539 , loss : 0.6552023823708888\n",
      "Epoch : 540 , loss : 0.6551996047412767\n",
      "Epoch : 541 , loss : 0.6551968360964974\n",
      "Epoch : 542 , loss : 0.6551940763835408\n",
      "Epoch : 543 , loss : 0.6551913255499477\n",
      "Epoch : 544 , loss : 0.6551885835438026\n",
      "Epoch : 545 , loss : 0.6551858503137243\n",
      "Epoch : 546 , loss : 0.6551831258088597\n",
      "Epoch : 547 , loss : 0.6551804099788753\n",
      "Epoch : 548 , loss : 0.65517770277395\n",
      "Epoch : 549 , loss : 0.6551750041447675\n",
      "Epoch : 550 , loss : 0.6551723140425095\n",
      "Epoch : 551 , loss : 0.6551696324188481\n",
      "Epoch : 552 , loss : 0.6551669592259393\n",
      "Epoch : 553 , loss : 0.6551642944164154\n",
      "Epoch : 554 , loss : 0.6551616379433793\n",
      "Epoch : 555 , loss : 0.6551589897603969\n",
      "Epoch : 556 , loss : 0.6551563498214908\n",
      "Epoch : 557 , loss : 0.6551537180811344\n",
      "Epoch : 558 , loss : 0.655151094494245\n",
      "Epoch : 559 , loss : 0.6551484790161772\n",
      "Epoch : 560 , loss : 0.6551458716027182\n",
      "Epoch : 561 , loss : 0.6551432722100804\n",
      "Epoch : 562 , loss : 0.6551406807948957\n",
      "Epoch : 563 , loss : 0.6551380973142108\n",
      "Epoch : 564 , loss : 0.65513552172548\n",
      "Epoch : 565 , loss : 0.6551329539865605\n",
      "Epoch : 566 , loss : 0.6551303940557061\n",
      "Epoch : 567 , loss : 0.6551278418915631\n",
      "Epoch : 568 , loss : 0.6551252974531634\n",
      "Epoch : 569 , loss : 0.6551227606999201\n",
      "Epoch : 570 , loss : 0.655120231591622\n",
      "Epoch : 571 , loss : 0.655117710088429\n",
      "Epoch : 572 , loss : 0.6551151961508663\n",
      "Epoch : 573 , loss : 0.6551126897398201\n",
      "Epoch : 574 , loss : 0.6551101908165321\n",
      "Epoch : 575 , loss : 0.6551076993425959\n",
      "Epoch : 576 , loss : 0.655105215279951\n",
      "Epoch : 577 , loss : 0.6551027385908788\n",
      "Epoch : 578 , loss : 0.6551002692379977\n",
      "Epoch : 579 , loss : 0.6550978071842596\n",
      "Epoch : 580 , loss : 0.655095352392944\n",
      "Epoch : 581 , loss : 0.6550929048276549\n",
      "Epoch : 582 , loss : 0.6550904644523161\n",
      "Epoch : 583 , loss : 0.6550880312311668\n",
      "Epoch : 584 , loss : 0.6550856051287575\n",
      "Epoch : 585 , loss : 0.6550831861099464\n",
      "Epoch : 586 , loss : 0.6550807741398951\n",
      "Epoch : 587 , loss : 0.6550783691840645\n",
      "Epoch : 588 , loss : 0.6550759712082109\n",
      "Epoch : 589 , loss : 0.6550735801783828\n",
      "Epoch : 590 , loss : 0.6550711960609162\n",
      "Epoch : 591 , loss : 0.6550688188224322\n",
      "Epoch : 592 , loss : 0.6550664484298314\n",
      "Epoch : 593 , loss : 0.6550640848502929\n",
      "Epoch : 594 , loss : 0.6550617280512682\n",
      "Epoch : 595 , loss : 0.6550593780004793\n",
      "Epoch : 596 , loss : 0.6550570346659152\n",
      "Epoch : 597 , loss : 0.655054698015828\n",
      "Epoch : 598 , loss : 0.65505236801873\n",
      "Epoch : 599 , loss : 0.6550500446433898\n",
      "Epoch : 600 , loss : 0.6550477278588301\n",
      "Epoch : 601 , loss : 0.6550454176343239\n",
      "Epoch : 602 , loss : 0.6550431139393913\n",
      "Epoch : 603 , loss : 0.6550408167437968\n",
      "Epoch : 604 , loss : 0.6550385260175461\n",
      "Epoch : 605 , loss : 0.6550362417308835\n",
      "Epoch : 606 , loss : 0.6550339638542879\n",
      "Epoch : 607 , loss : 0.6550316923584715\n",
      "Epoch : 608 , loss : 0.6550294272143755\n",
      "Epoch : 609 , loss : 0.6550271683931685\n",
      "Epoch : 610 , loss : 0.6550249158662428\n",
      "Epoch : 611 , loss : 0.6550226696052122\n",
      "Epoch : 612 , loss : 0.6550204295819095\n",
      "Epoch : 613 , loss : 0.6550181957683834\n",
      "Epoch : 614 , loss : 0.6550159681368961\n",
      "Epoch : 615 , loss : 0.655013746659921\n",
      "Epoch : 616 , loss : 0.6550115313101398\n",
      "Epoch : 617 , loss : 0.6550093220604405\n",
      "Epoch : 618 , loss : 0.6550071188839144\n",
      "Epoch : 619 , loss : 0.6550049217538538\n",
      "Epoch : 620 , loss : 0.6550027306437507\n",
      "Epoch : 621 , loss : 0.6550005455272929\n",
      "Epoch : 622 , loss : 0.6549983663783625\n",
      "Epoch : 623 , loss : 0.6549961931710339\n",
      "Epoch : 624 , loss : 0.654994025879571\n",
      "Epoch : 625 , loss : 0.6549918644784253\n",
      "Epoch : 626 , loss : 0.654989708942234\n",
      "Epoch : 627 , loss : 0.654987559245817\n",
      "Epoch : 628 , loss : 0.6549854153641761\n",
      "Epoch : 629 , loss : 0.6549832772724918\n",
      "Epoch : 630 , loss : 0.6549811449461219\n",
      "Epoch : 631 , loss : 0.6549790183605994\n",
      "Epoch : 632 , loss : 0.65497689749163\n",
      "Epoch : 633 , loss : 0.6549747823150908\n",
      "Epoch : 634 , loss : 0.6549726728070286\n",
      "Epoch : 635 , loss : 0.6549705689436573\n",
      "Epoch : 636 , loss : 0.6549684707013562\n",
      "Epoch : 637 , loss : 0.6549663780566684\n",
      "Epoch : 638 , loss : 0.6549642909862989\n",
      "Epoch : 639 , loss : 0.6549622094671128\n",
      "Epoch : 640 , loss : 0.6549601334761338\n",
      "Epoch : 641 , loss : 0.6549580629905419\n",
      "Epoch : 642 , loss : 0.6549559979876722\n",
      "Epoch : 643 , loss : 0.6549539384450132\n",
      "Epoch : 644 , loss : 0.6549518843402046\n",
      "Epoch : 645 , loss : 0.6549498356510363\n",
      "Epoch : 646 , loss : 0.6549477923554466\n",
      "Epoch : 647 , loss : 0.6549457544315208\n",
      "Epoch : 648 , loss : 0.6549437218574888\n",
      "Epoch : 649 , loss : 0.6549416946117247\n",
      "Epoch : 650 , loss : 0.6549396726727442\n",
      "Epoch : 651 , loss : 0.6549376560192045\n",
      "Epoch : 652 , loss : 0.6549356446299013\n",
      "Epoch : 653 , loss : 0.654933638483768\n",
      "Epoch : 654 , loss : 0.6549316375598744\n",
      "Epoch : 655 , loss : 0.6549296418374255\n",
      "Epoch : 656 , loss : 0.6549276512957595\n",
      "Epoch : 657 , loss : 0.6549256659143464\n",
      "Epoch : 658 , loss : 0.6549236856727875\n",
      "Epoch : 659 , loss : 0.654921710550813\n",
      "Epoch : 660 , loss : 0.6549197405282815\n",
      "Epoch : 661 , loss : 0.6549177755851783\n",
      "Epoch : 662 , loss : 0.654915815701614\n",
      "Epoch : 663 , loss : 0.6549138608578233\n",
      "Epoch : 664 , loss : 0.6549119110341647\n",
      "Epoch : 665 , loss : 0.6549099662111174\n",
      "Epoch : 666 , loss : 0.6549080263692816\n",
      "Epoch : 667 , loss : 0.6549060914893772\n",
      "Epoch : 668 , loss : 0.6549041615522413\n",
      "Epoch : 669 , loss : 0.6549022365388286\n",
      "Epoch : 670 , loss : 0.65490031643021\n",
      "Epoch : 671 , loss : 0.6548984012075701\n",
      "Epoch : 672 , loss : 0.6548964908522078\n",
      "Epoch : 673 , loss : 0.6548945853455341\n",
      "Epoch : 674 , loss : 0.6548926846690717\n",
      "Epoch : 675 , loss : 0.6548907888044533\n",
      "Epoch : 676 , loss : 0.6548888977334208\n",
      "Epoch : 677 , loss : 0.6548870114378245\n",
      "Epoch : 678 , loss : 0.6548851298996218\n",
      "Epoch : 679 , loss : 0.6548832531008761\n",
      "Epoch : 680 , loss : 0.6548813810237563\n",
      "Epoch : 681 , loss : 0.6548795136505348\n",
      "Epoch : 682 , loss : 0.6548776509635876\n",
      "Epoch : 683 , loss : 0.6548757929453929\n",
      "Epoch : 684 , loss : 0.6548739395785299\n",
      "Epoch : 685 , loss : 0.6548720908456782\n",
      "Epoch : 686 , loss : 0.6548702467296168\n",
      "Epoch : 687 , loss : 0.6548684072132231\n",
      "Epoch : 688 , loss : 0.654866572279472\n",
      "Epoch : 689 , loss : 0.6548647419114348\n",
      "Epoch : 690 , loss : 0.6548629160922794\n",
      "Epoch : 691 , loss : 0.6548610948052674\n",
      "Epoch : 692 , loss : 0.6548592780337553\n",
      "Epoch : 693 , loss : 0.6548574657611926\n",
      "Epoch : 694 , loss : 0.654855657971121\n",
      "Epoch : 695 , loss : 0.6548538546471734\n",
      "Epoch : 696 , loss : 0.654852055773074\n",
      "Epoch : 697 , loss : 0.6548502613326367\n",
      "Epoch : 698 , loss : 0.6548484713097641\n",
      "Epoch : 699 , loss : 0.6548466856884478\n",
      "Epoch : 700 , loss : 0.6548449044527663\n",
      "Epoch : 701 , loss : 0.654843127586885\n",
      "Epoch : 702 , loss : 0.6548413550750554\n",
      "Epoch : 703 , loss : 0.6548395869016144\n",
      "Epoch : 704 , loss : 0.6548378230509829\n",
      "Epoch : 705 , loss : 0.6548360635076662\n",
      "Epoch : 706 , loss : 0.6548343082562522\n",
      "Epoch : 707 , loss : 0.6548325572814114\n",
      "Epoch : 708 , loss : 0.654830810567896\n",
      "Epoch : 709 , loss : 0.654829068100539\n",
      "Epoch : 710 , loss : 0.6548273298642535\n",
      "Epoch : 711 , loss : 0.6548255958440324\n",
      "Epoch : 712 , loss : 0.6548238660249475\n",
      "Epoch : 713 , loss : 0.6548221403921488\n",
      "Epoch : 714 , loss : 0.6548204189308643\n",
      "Epoch : 715 , loss : 0.6548187016263982\n",
      "Epoch : 716 , loss : 0.6548169884641315\n",
      "Epoch : 717 , loss : 0.6548152794295211\n",
      "Epoch : 718 , loss : 0.6548135745080984\n",
      "Epoch : 719 , loss : 0.6548118736854697\n",
      "Epoch : 720 , loss : 0.6548101769473149\n",
      "Epoch : 721 , loss : 0.6548084842793873\n",
      "Epoch : 722 , loss : 0.6548067956675128\n",
      "Epoch : 723 , loss : 0.6548051110975892\n",
      "Epoch : 724 , loss : 0.6548034305555862\n",
      "Epoch : 725 , loss : 0.6548017540275441\n",
      "Epoch : 726 , loss : 0.6548000814995736\n",
      "Epoch : 727 , loss : 0.654798412957855\n",
      "Epoch : 728 , loss : 0.6547967483886383\n",
      "Epoch : 729 , loss : 0.6547950877782419\n",
      "Epoch : 730 , loss : 0.6547934311130522\n",
      "Epoch : 731 , loss : 0.6547917783795237\n",
      "Epoch : 732 , loss : 0.6547901295641775\n",
      "Epoch : 733 , loss : 0.6547884846536014\n",
      "Epoch : 734 , loss : 0.6547868436344494\n",
      "Epoch : 735 , loss : 0.6547852064934411\n",
      "Epoch : 736 , loss : 0.6547835732173608\n",
      "Epoch : 737 , loss : 0.6547819437930575\n",
      "Epoch : 738 , loss : 0.6547803182074445\n",
      "Epoch : 739 , loss : 0.6547786964474984\n",
      "Epoch : 740 , loss : 0.654777078500259\n",
      "Epoch : 741 , loss : 0.6547754643528284\n",
      "Epoch : 742 , loss : 0.6547738539923713\n",
      "Epoch : 743 , loss : 0.6547722474061136\n",
      "Epoch : 744 , loss : 0.654770644581343\n",
      "Epoch : 745 , loss : 0.6547690455054074\n",
      "Epoch : 746 , loss : 0.6547674501657154\n",
      "Epoch : 747 , loss : 0.6547658585497349\n",
      "Epoch : 748 , loss : 0.6547642706449939\n",
      "Epoch : 749 , loss : 0.6547626864390791\n",
      "Epoch : 750 , loss : 0.6547611059196357\n",
      "Epoch : 751 , loss : 0.6547595290743666\n",
      "Epoch : 752 , loss : 0.6547579558910336\n",
      "Epoch : 753 , loss : 0.6547563863574547\n",
      "Epoch : 754 , loss : 0.654754820461505\n",
      "Epoch : 755 , loss : 0.6547532581911164\n",
      "Epoch : 756 , loss : 0.6547516995342766\n",
      "Epoch : 757 , loss : 0.6547501444790291\n",
      "Epoch : 758 , loss : 0.6547485930134725\n",
      "Epoch : 759 , loss : 0.6547470451257604\n",
      "Epoch : 760 , loss : 0.654745500804101\n",
      "Epoch : 761 , loss : 0.6547439600367564\n",
      "Epoch : 762 , loss : 0.6547424228120425\n",
      "Epoch : 763 , loss : 0.6547408891183285\n",
      "Epoch : 764 , loss : 0.654739358944037\n",
      "Epoch : 765 , loss : 0.6547378322776425\n",
      "Epoch : 766 , loss : 0.6547363091076726\n",
      "Epoch : 767 , loss : 0.6547347894227061\n",
      "Epoch : 768 , loss : 0.6547332732113734\n",
      "Epoch : 769 , loss : 0.6547317604623569\n",
      "Epoch : 770 , loss : 0.6547302511643887\n",
      "Epoch : 771 , loss : 0.654728745306252\n",
      "Epoch : 772 , loss : 0.6547272428767806\n",
      "Epoch : 773 , loss : 0.654725743864857\n",
      "Epoch : 774 , loss : 0.6547242482594143\n",
      "Epoch : 775 , loss : 0.6547227560494341\n",
      "Epoch : 776 , loss : 0.6547212672239471\n",
      "Epoch : 777 , loss : 0.6547197817720324\n",
      "Epoch : 778 , loss : 0.6547182996828171\n",
      "Epoch : 779 , loss : 0.6547168209454768\n",
      "Epoch : 780 , loss : 0.6547153455492339\n",
      "Epoch : 781 , loss : 0.6547138734833586\n",
      "Epoch : 782 , loss : 0.6547124047371677\n",
      "Epoch : 783 , loss : 0.6547109393000248\n",
      "Epoch : 784 , loss : 0.6547094771613399\n",
      "Epoch : 785 , loss : 0.6547080183105689\n",
      "Epoch : 786 , loss : 0.6547065627372132\n",
      "Epoch : 787 , loss : 0.6547051104308201\n",
      "Epoch : 788 , loss : 0.6547036613809819\n",
      "Epoch : 789 , loss : 0.6547022155773355\n",
      "Epoch : 790 , loss : 0.654700773009563\n",
      "Epoch : 791 , loss : 0.6546993336673899\n",
      "Epoch : 792 , loss : 0.6546978975405866\n",
      "Epoch : 793 , loss : 0.6546964646189665\n",
      "Epoch : 794 , loss : 0.654695034892387\n",
      "Epoch : 795 , loss : 0.6546936083507485\n",
      "Epoch : 796 , loss : 0.6546921849839945\n",
      "Epoch : 797 , loss : 0.6546907647821105\n",
      "Epoch : 798 , loss : 0.6546893477351257\n",
      "Epoch : 799 , loss : 0.6546879338331096\n",
      "Epoch : 800 , loss : 0.6546865230661756\n",
      "Epoch : 801 , loss : 0.654685115424477\n",
      "Epoch : 802 , loss : 0.6546837108982096\n",
      "Epoch : 803 , loss : 0.6546823094776096\n",
      "Epoch : 804 , loss : 0.6546809111529549\n",
      "Epoch : 805 , loss : 0.6546795159145629\n",
      "Epoch : 806 , loss : 0.6546781237527921\n",
      "Epoch : 807 , loss : 0.6546767346580411\n",
      "Epoch : 808 , loss : 0.6546753486207485\n",
      "Epoch : 809 , loss : 0.654673965631392\n",
      "Epoch : 810 , loss : 0.654672585680489\n",
      "Epoch : 811 , loss : 0.6546712087585963\n",
      "Epoch : 812 , loss : 0.6546698348563095\n",
      "Epoch : 813 , loss : 0.6546684639642628\n",
      "Epoch : 814 , loss : 0.6546670960731292\n",
      "Epoch : 815 , loss : 0.6546657311736196\n",
      "Epoch : 816 , loss : 0.6546643692564831\n",
      "Epoch : 817 , loss : 0.6546630103125067\n",
      "Epoch : 818 , loss : 0.6546616543325147\n",
      "Epoch : 819 , loss : 0.6546603013073694\n",
      "Epoch : 820 , loss : 0.6546589512279695\n",
      "Epoch : 821 , loss : 0.6546576040852514\n",
      "Epoch : 822 , loss : 0.6546562598701877\n",
      "Epoch : 823 , loss : 0.6546549185737877\n",
      "Epoch : 824 , loss : 0.654653580187097\n",
      "Epoch : 825 , loss : 0.6546522447011975\n",
      "Epoch : 826 , loss : 0.6546509121072067\n",
      "Epoch : 827 , loss : 0.6546495823962784\n",
      "Epoch : 828 , loss : 0.6546482555596007\n",
      "Epoch : 829 , loss : 0.6546469315883987\n",
      "Epoch : 830 , loss : 0.654645610473931\n",
      "Epoch : 831 , loss : 0.6546442922074922\n",
      "Epoch : 832 , loss : 0.6546429767804112\n",
      "Epoch : 833 , loss : 0.6546416641840513\n",
      "Epoch : 834 , loss : 0.6546403544098107\n",
      "Epoch : 835 , loss : 0.6546390474491208\n",
      "Epoch : 836 , loss : 0.6546377432934479\n",
      "Epoch : 837 , loss : 0.6546364419342917\n",
      "Epoch : 838 , loss : 0.6546351433631852\n",
      "Epoch : 839 , loss : 0.6546338475716953\n",
      "Epoch : 840 , loss : 0.654632554551422\n",
      "Epoch : 841 , loss : 0.654631264293998\n",
      "Epoch : 842 , loss : 0.654629976791089\n",
      "Epoch : 843 , loss : 0.6546286920343938\n",
      "Epoch : 844 , loss : 0.6546274100156432\n",
      "Epoch : 845 , loss : 0.6546261307266006\n",
      "Epoch : 846 , loss : 0.6546248541590614\n",
      "Epoch : 847 , loss : 0.6546235803048532\n",
      "Epoch : 848 , loss : 0.654622309155835\n",
      "Epoch : 849 , loss : 0.654621040703898\n",
      "Epoch : 850 , loss : 0.6546197749409645\n",
      "Epoch : 851 , loss : 0.6546185118589884\n",
      "Epoch : 852 , loss : 0.6546172514499543\n",
      "Epoch : 853 , loss : 0.6546159937058783\n",
      "Epoch : 854 , loss : 0.654614738618807\n",
      "Epoch : 855 , loss : 0.6546134861808178\n",
      "Epoch : 856 , loss : 0.6546122363840182\n",
      "Epoch : 857 , loss : 0.6546109892205468\n",
      "Epoch : 858 , loss : 0.6546097446825719\n",
      "Epoch : 859 , loss : 0.6546085027622917\n",
      "Epoch : 860 , loss : 0.6546072634519347\n",
      "Epoch : 861 , loss : 0.6546060267437586\n",
      "Epoch : 862 , loss : 0.654604792630051\n",
      "Epoch : 863 , loss : 0.6546035611031292\n",
      "Epoch : 864 , loss : 0.6546023321553391\n",
      "Epoch : 865 , loss : 0.6546011057790563\n",
      "Epoch : 866 , loss : 0.6545998819666846\n",
      "Epoch : 867 , loss : 0.6545986607106575\n",
      "Epoch : 868 , loss : 0.6545974420034372\n",
      "Epoch : 869 , loss : 0.6545962258375132\n",
      "Epoch : 870 , loss : 0.6545950122054047\n",
      "Epoch : 871 , loss : 0.6545938010996586\n",
      "Epoch : 872 , loss : 0.6545925925128497\n",
      "Epoch : 873 , loss : 0.6545913864375813\n",
      "Epoch : 874 , loss : 0.6545901828664842\n",
      "Epoch : 875 , loss : 0.6545889817922166\n",
      "Epoch : 876 , loss : 0.654587783207465\n",
      "Epoch : 877 , loss : 0.6545865871049424\n",
      "Epoch : 878 , loss : 0.65458539347739\n",
      "Epoch : 879 , loss : 0.6545842023175752\n",
      "Epoch : 880 , loss : 0.6545830136182932\n",
      "Epoch : 881 , loss : 0.6545818273723654\n",
      "Epoch : 882 , loss : 0.6545806435726406\n",
      "Epoch : 883 , loss : 0.6545794622119937\n",
      "Epoch : 884 , loss : 0.6545782832833263\n",
      "Epoch : 885 , loss : 0.6545771067795664\n",
      "Epoch : 886 , loss : 0.6545759326936678\n",
      "Epoch : 887 , loss : 0.6545747610186109\n",
      "Epoch : 888 , loss : 0.6545735917474019\n",
      "Epoch : 889 , loss : 0.654572424873073\n",
      "Epoch : 890 , loss : 0.6545712603886815\n",
      "Epoch : 891 , loss : 0.6545700982873109\n",
      "Epoch : 892 , loss : 0.6545689385620704\n",
      "Epoch : 893 , loss : 0.6545677812060937\n",
      "Epoch : 894 , loss : 0.65456662621254\n",
      "Epoch : 895 , loss : 0.6545654735745943\n",
      "Epoch : 896 , loss : 0.6545643232854658\n",
      "Epoch : 897 , loss : 0.654563175338389\n",
      "Epoch : 898 , loss : 0.6545620297266228\n",
      "Epoch : 899 , loss : 0.6545608864434508\n",
      "Epoch : 900 , loss : 0.6545597454821817\n",
      "Epoch : 901 , loss : 0.6545586068361475\n",
      "Epoch : 902 , loss : 0.6545574704987058\n",
      "Epoch : 903 , loss : 0.6545563364632373\n",
      "Epoch : 904 , loss : 0.6545552047231471\n",
      "Epoch : 905 , loss : 0.6545540752718647\n",
      "Epoch : 906 , loss : 0.6545529481028426\n",
      "Epoch : 907 , loss : 0.6545518232095581\n",
      "Epoch : 908 , loss : 0.6545507005855109\n",
      "Epoch : 909 , loss : 0.6545495802242248\n",
      "Epoch : 910 , loss : 0.6545484621192473\n",
      "Epoch : 911 , loss : 0.6545473462641489\n",
      "Epoch : 912 , loss : 0.6545462326525232\n",
      "Epoch : 913 , loss : 0.6545451212779867\n",
      "Epoch : 914 , loss : 0.6545440121341796\n",
      "Epoch : 915 , loss : 0.6545429052147641\n",
      "Epoch : 916 , loss : 0.6545418005134255\n",
      "Epoch : 917 , loss : 0.6545406980238723\n",
      "Epoch : 918 , loss : 0.6545395977398345\n",
      "Epoch : 919 , loss : 0.6545384996550653\n",
      "Epoch : 920 , loss : 0.6545374037633401\n",
      "Epoch : 921 , loss : 0.6545363100584565\n",
      "Epoch : 922 , loss : 0.6545352185342341\n",
      "Epoch : 923 , loss : 0.6545341291845151\n",
      "Epoch : 924 , loss : 0.6545330420031629\n",
      "Epoch : 925 , loss : 0.6545319569840632\n",
      "Epoch : 926 , loss : 0.6545308741211233\n",
      "Epoch : 927 , loss : 0.6545297934082723\n",
      "Epoch : 928 , loss : 0.6545287148394606\n",
      "Epoch : 929 , loss : 0.6545276384086605\n",
      "Epoch : 930 , loss : 0.6545265641098649\n",
      "Epoch : 931 , loss : 0.654525491937089\n",
      "Epoch : 932 , loss : 0.6545244218843685\n",
      "Epoch : 933 , loss : 0.65452335394576\n",
      "Epoch : 934 , loss : 0.6545222881153419\n",
      "Epoch : 935 , loss : 0.6545212243872125\n",
      "Epoch : 936 , loss : 0.6545201627554917\n",
      "Epoch : 937 , loss : 0.6545191032143199\n",
      "Epoch : 938 , loss : 0.6545180457578579\n",
      "Epoch : 939 , loss : 0.6545169903802872\n",
      "Epoch : 940 , loss : 0.6545159370758096\n",
      "Epoch : 941 , loss : 0.6545148858386477\n",
      "Epoch : 942 , loss : 0.6545138366630433\n",
      "Epoch : 943 , loss : 0.65451278954326\n",
      "Epoch : 944 , loss : 0.6545117444735801\n",
      "Epoch : 945 , loss : 0.6545107014483066\n",
      "Epoch : 946 , loss : 0.6545096604617618\n",
      "Epoch : 947 , loss : 0.6545086215082887\n",
      "Epoch : 948 , loss : 0.6545075845822494\n",
      "Epoch : 949 , loss : 0.6545065496780258\n",
      "Epoch : 950 , loss : 0.6545055167900193\n",
      "Epoch : 951 , loss : 0.6545044859126512\n",
      "Epoch : 952 , loss : 0.6545034570403614\n",
      "Epoch : 953 , loss : 0.6545024301676101\n",
      "Epoch : 954 , loss : 0.6545014052888758\n",
      "Epoch : 955 , loss : 0.6545003823986569\n",
      "Epoch : 956 , loss : 0.6544993614914707\n",
      "Epoch : 957 , loss : 0.6544983425618528\n",
      "Epoch : 958 , loss : 0.6544973256043586\n",
      "Epoch : 959 , loss : 0.6544963106135622\n",
      "Epoch : 960 , loss : 0.6544952975840558\n",
      "Epoch : 961 , loss : 0.6544942865104513\n",
      "Epoch : 962 , loss : 0.6544932773873781\n",
      "Epoch : 963 , loss : 0.6544922702094847\n",
      "Epoch : 964 , loss : 0.6544912649714381\n",
      "Epoch : 965 , loss : 0.6544902616679233\n",
      "Epoch : 966 , loss : 0.6544892602936443\n",
      "Epoch : 967 , loss : 0.6544882608433223\n",
      "Epoch : 968 , loss : 0.6544872633116973\n",
      "Epoch : 969 , loss : 0.654486267693527\n",
      "Epoch : 970 , loss : 0.6544852739835876\n",
      "Epoch : 971 , loss : 0.6544842821766725\n",
      "Epoch : 972 , loss : 0.6544832922675935\n",
      "Epoch : 973 , loss : 0.6544823042511797\n",
      "Epoch : 974 , loss : 0.6544813181222783\n",
      "Epoch : 975 , loss : 0.6544803338757537\n",
      "Epoch : 976 , loss : 0.6544793515064883\n",
      "Epoch : 977 , loss : 0.6544783710093814\n",
      "Epoch : 978 , loss : 0.6544773923793501\n",
      "Epoch : 979 , loss : 0.6544764156113289\n",
      "Epoch : 980 , loss : 0.654475440700269\n",
      "Epoch : 981 , loss : 0.6544744676411391\n",
      "Epoch : 982 , loss : 0.6544734964289252\n",
      "Epoch : 983 , loss : 0.65447252705863\n",
      "Epoch : 984 , loss : 0.6544715595252734\n",
      "Epoch : 985 , loss : 0.6544705938238918\n",
      "Epoch : 986 , loss : 0.6544696299495391\n",
      "Epoch : 987 , loss : 0.6544686678972851\n",
      "Epoch : 988 , loss : 0.6544677076622171\n",
      "Epoch : 989 , loss : 0.6544667492394384\n",
      "Epoch : 990 , loss : 0.6544657926240691\n",
      "Epoch : 991 , loss : 0.6544648378112461\n",
      "Epoch : 992 , loss : 0.6544638847961218\n",
      "Epoch : 993 , loss : 0.6544629335738661\n",
      "Epoch : 994 , loss : 0.6544619841396643\n",
      "Epoch : 995 , loss : 0.6544610364887182\n",
      "Epoch : 996 , loss : 0.6544600906162459\n",
      "Epoch : 997 , loss : 0.6544591465174813\n",
      "Epoch : 998 , loss : 0.6544582041876746\n",
      "Epoch : 999 , loss : 0.6544572636220917\n",
      "Epoch : 1000 , loss : 0.6544563248160149\n"
     ]
    }
   ],
   "source": [
    "model = SimpleNN(x_train_tensor)\n",
    "for epoch in range(epochs):\n",
    "    y_pred = model.forward(x_train_tensor)\n",
    "    loss = model.loss_function(y_pred,y_train_tensor)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        model.weights -= learning_rate * model.weights.grad\n",
    "        model.bias -= learning_rate * model.bias.grad\n",
    "    model.weights.grad.zero_()\n",
    "    model.bias.grad.zero_()\n",
    "\n",
    "    print(f'Epoch : {epoch+1} , loss : {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34eb6808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 57.894736528396606 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = model.forward(X_test_tensor)\n",
    "    y_pred = (y_pred > 0.9).float()\n",
    "    accuracy = (y_pred == y_test_tensor).float().mean()\n",
    "    print(f'Test Accuracy : {accuracy.item()*100} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9bb45a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a31a13c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f46f33d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ee61ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043c995c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1598e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c004c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5b688e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ec848b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f26572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6022f8a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a69b10d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4079c55d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680443f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee14989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eea454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7c7946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471f9971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559d226c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

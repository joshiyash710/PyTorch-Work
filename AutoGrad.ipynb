{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59aae70a",
   "metadata": {},
   "source": [
    "#### AutoGrad is basically the tool in PyTorch for computing the gradients automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f48efa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c3036c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.7000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(6.7)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c79c046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a37886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor(2.0, requires_grad=True)\n",
    "b = torch.tensor(1.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce80dbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = w * x + b \n",
    "y_pred = torch.sigmoid(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d83da594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(y_pred, y):\n",
    "    epsilon = 1e-7  # small constant to avoid log(0)\n",
    "    y_pred = torch.clamp(y_pred, epsilon, 1 - epsilon)\n",
    "    bce = - (y * torch.log(y_pred) + (1 - y) * torch.log(1 - y_pred))\n",
    "    return bce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12b86ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = binary_cross_entropy(y_pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ad09e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward() # compute gradients for w and b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1dd02fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.3329, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e96d807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(6.7000), tensor(1.0000))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.grad , b.grad ## gradients of w and b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15dc2b4",
   "metadata": {},
   "source": [
    "##### So , in this way AutoGrad keeps the track of the operations and when told to compute the gradients of the parameters it computes automatically and returns thus reducing the immensly complex calculations of computing gradients manually "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125fc10c",
   "metadata": {},
   "source": [
    "### AutoGrad for vector of inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddce8715",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.tensor([1.0,2.0,3.0,4.0,5.0],requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d61ea0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5.], requires_grad=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36162b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11., grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = (x1**2).mean()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5318dc8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11., grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918087f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4000, 0.8000, 1.2000, 1.6000, 2.0000])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.grad ## gradient of y with respect to x1 , x2 ,x3 ,x4 ,x5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb41999",
   "metadata": {},
   "source": [
    "## Clearing out gradients "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41d6e47",
   "metadata": {},
   "source": [
    "##### Clearing out of gradients is necessary because on repetative computation the gradients gets accumulated , so to avoid that the gradients must be cleared out after each iteration. There are 3 methods of doing it : \n",
    "\n",
    "#####                    1. requires_grad = False\n",
    "#####                    2. detach()\n",
    "#####                    3. no_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44ac3ec",
   "metadata": {},
   "source": [
    "#### 1. Using requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c83d4f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., requires_grad=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(1.0, requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0ae62d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ae0b7a",
   "metadata": {},
   "source": [
    "#### 2. Using detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aac349b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., requires_grad=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(1.0, requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3a2841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.detach()\n",
    "y ## new tensor with no gradient tracking and same value as x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fdc650",
   "metadata": {},
   "source": [
    "#### 3. Using no_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "442fa7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., requires_grad=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(1.0, requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204b5423",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y = x ** 2 ## no gradient will be tracked for y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9b2ced",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55aa1ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a00176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79cff62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5fab01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
